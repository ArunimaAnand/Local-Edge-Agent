# Local Agent Documentation

A simple Python agent framework that connects to a local LLM (via LM Studio) and can call custom Python tools/functions based on LLM output. The agent interprets LLM responses, detects tool calls, executes them, and returns the final answer.

## General Setup

From here, please navigate to the instructions for the model backend you want to use:
- [AnythingLLM Backend Instructions](#anythingllm-backend)
- [LM Studio Backend Instructions](#lm-studio-backend)
- [Nexa Backend Instructions](#nexa-backend)

## AnythingLLM Backend

AnythingLLM is an open-source all-in-one language model app that can be run locally. To use the AnythingLLM backend with Local Agent, follow these steps:

### Setup
### Usage

## LM Studio Backend

### Setup
### Usage

## Nexa Backend

### Setup
### Usage